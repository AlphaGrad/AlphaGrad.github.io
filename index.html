<!DOCTYPE html>
<html>
<head>
  <meta charset="utf-8">
  <meta name="description"
        content="Normalized Gradient Descent for Adaptive Multi-loss Functions in EEG-based Motor Imagery Classification.">
  <meta name="keywords" content="AlphaGrad, Brain-computer interfaces, multi-task learning, adaptive loss blending, motor imagery EEG, normalized gradient descent">
  <meta name="viewport" content="width=device-width, initial-scale=1">
  <title>AlphaGrad</title>

  <!-- Global site tag (gtag.js) - Google Analytics -->
  <!-- <script async src="https://www.googletagmanager.com/gtag/js?id=G-PYVRSFMDRL"></script>
  <script>
    window.dataLayer = window.dataLayer || [];

    function gtag() {
      dataLayer.push(arguments);
    }

    gtag('js', new Date());

    gtag('config', 'G-PYVRSFMDRL');
  </script> -->

  <link href="https://fonts.googleapis.com/css?family=Google+Sans|Noto+Sans|Castoro"
        rel="stylesheet">

  <link rel="stylesheet" href="./static/css/bulma.min.css">
  <link rel="stylesheet" href="./static/css/bulma-carousel.min.css">
  <link rel="stylesheet" href="./static/css/bulma-slider.min.css">
  <link rel="stylesheet" href="./static/css/fontawesome.all.min.css">
  <link rel="stylesheet"
        href="https://cdn.jsdelivr.net/gh/jpswalsh/academicons@1/css/academicons.min.css">
  <link rel="stylesheet" href="./static/css/index.css">
  <!-- <link rel="icon" href="./static/images/favicon.svg"> -->
  <link rel="apple-touch-icon" sizes="180x180" href="./static/favicon/apple-touch-icon.png">
  <link rel="icon" type="image/png" sizes="32x32" href="./static/favicon/favicon-32x32.png">
  <link rel="icon" type="image/png" sizes="16x16" href="./static/favicon/favicon-16x16.png">
  <link rel="manifest" href="/site.webmanifest">

  <script src="https://ajax.googleapis.com/ajax/libs/jquery/3.5.1/jquery.min.js"></script>
  <script defer src="./static/js/fontawesome.all.min.js"></script>
  <script src="./static/js/bulma-carousel.min.js"></script>
  <script src="./static/js/bulma-slider.min.js"></script>
  <script src="./static/js/index.js"></script>

</head>
<body>

<nav class="navbar" role="navigation" aria-label="main navigation">
  <div class="navbar-brand">
    <a role="button" class="navbar-burger" aria-label="menu" aria-expanded="false">
      <span aria-hidden="true"></span>
      <span aria-hidden="true"></span>
      <span aria-hidden="true"></span>
    </a>
  </div>
  <div class="navbar-menu">
    <div class="navbar-start" style="flex-grow: 1; justify-content: center;">
      <a class="navbar-item" href="https://xydxdy.github.io">
      <span class="icon">
          <i class="fas fa-home"></i>
      </span>
      </a>

      <div class="navbar-item has-dropdown is-hoverable">
        <a class="navbar-link">
          More Research
        </a>
        <div class="navbar-dropdown">
          <a class="navbar-item" href="https://AlphaGrad.github.io">
            AlphaGrad
          </a>
          <a class="navbar-item" href="https://mixnetbci.github.io">
            MixNet
          </a>
          <a class="navbar-item" href="https://min2net.github.io">
            MIN2Net
          </a>
        </div>
      </div>
    </div>

  </div>
</nav>


<section class="hero">
  <div class="hero-body">
    <div class="container is-max-desktop">
      <div class="columns is-centered">
        <div class="column has-text-centered">
          <h1 class="title is-1 publication-title">AlphaGrad: Normalized Gradient Descent for Adaptive Multi-loss Functions in EEG-based Motor Imagery Classification</h1>
          <div class="is-size-5 publication-authors">
            <span class="author-block">
              <a href="https://xydxdy.github.io">Rattanaphon Chaisaen<sup>1*</sup></a>
              <a href="https://orcid.org/0000-0003-1521-9956" aria-label="View ORCID record">
                <img src="static/images/ORCID_iD.png" alt="ORCID iD" width="24px" height="24px"/>
              </a>,
            </span>
            <span class="author-block">
              <a href="https://max-phairot-a.github.io">Phairot Autthasan<sup>1*</sup></a>
              <a href="https://orcid.org/0000-0002-9566-8382" aria-label="View ORCID record">
                <img src="static/images/ORCID_iD.png" alt="ORCID iD" width="24px" height="24px"/>
              </a>,
            </span>
            <span class="author-block">
              <a href="https://scholar.google.co.th/citations?user=d08AqsIAAAAJ&hl=en">Apiwat Ditthapron<sup>2</sup></a>
              <a href="https://orcid.org/0000-0002-1525-8421" aria-label="View ORCID record">
                <img src="static/images/ORCID_iD.png" alt="ORCID iD" width="24px" height="24px"/>
              </a>,
            </span>
            <span class="author-block">
              <a href="https://theerawitw.github.io">Theerawit Wilaiprasitporn<sup>1</sup></a>
              <a href="https://orcid.org/0000-0003-4941-4354" aria-label="View ORCID record">
                <img src="static/images/ORCID_iD.png" alt="ORCID iD" width="24px" height="24px"/>
              </a>
            </span>
          </div>

          <div class="is-size-5 publication-authors">
            <span class="author-block"><sup>1</sup>Vidyasirimedhi Institute of Science & Technology (VISTEC),</span>
            <span class="author-block"><sup>2</sup>Rajamangala University of Technology Krungthep</span>
          </div>
          <div class="is-size-5 publication-authors">
            <span class="author-block"><sup>*</sup>Indicates Equal Contribution</span>
          </div>

          <div class="column has-text-centered">
            <div class="publication-links">
              <span class="link-block">
                <a href="https://doi.org/10.1109/JBHI.2025.3572197"
                   class="external-link button is-normal is-rounded is-dark"
                   style="opacity: 1;">
                  <span class="icon">
                      <i class="fas fa-file-pdf"></i>
                  </span>
                  <span>Paper</span>
                </a>
              </span>
              <span class="link-block">
                <a href="https://arxiv.org/"
                   class="external-link button is-normal is-rounded is-dark"
                   style="opacity: 1;">
                  <span class="icon">
                      <i class="ai ai-arxiv"></i>
                  </span>
                  <span>arXiv</span>
                </a>
              </span>
              <span class="link-block">
                <a href="https://github.com/xydxdy/AlphaGrad"
                   class="external-link button is-normal is-rounded is-dark"
                   style="opacity: 1;">
                  <span class="icon">
                      <i class="fab fa-github"></i>
                  </span>
                  <span>Code</span>
                  </a>
              </span>
              <span class="link-block">
                <a href="static/pdf/Supplementary-material.pdf"
                   class="external-link button is-normal is-rounded is-dark"
                   style="opacity: 1;">
                  <span class="icon">
                      <i class="fa fa-file"></i>
                  </span>
                  <span>Supplementary Material</span>
                  </a>
              </span>
            </div>
          </div>
        </div>
      </div>
    </div>
  </div>
</section>




<!-- <section class="section">
  <div class="container is-max-desktop">
    <div class="columns is-centered has-text-centered">
      <div class="column is-four-fifths">
        <h1 class="title is-3">Abstract</h1>
      </div>
    </div>
  </div>
</section> -->

<section class="section">
  <div class="container is-max-desktop">
    <img src="./static/images/GA-web.png"
         alt="AlphaGrad"
         class="image normal-img-scale-center"
         id="clickable-image-0">
  </div>
</section>

<!-- Modal -->
<div class="modal" id="image-modal-0">
  <div class="modal-background"></div>
  <div class="modal-content">
    <img src="./static/images/GA-web.png" alt="AlphaGrad">
  </div>
  <button class="modal-close is-large" aria-label="close"></button>
</div>


<section class="section">
  <div class="container is-max-desktop">
    <!-- Abstract. -->
    <div class="columns is-centered has-text-centered">
      <div class="column is-four-fifths">
        <h2 class="title is-3">Abstract</h2>
        <div class="content has-text-justified">
          <p>
            In this study, we propose AlphaGrad, a novel adaptive loss blending strategy for optimizing multi-task learning (MTL) models in motor imagery (MI)-based 
            electroencephalography (EEG) classification. AlphaGrad is the first method to automatically adjust multi-loss functions with differing metric scales, 
            including mean square error, cross-entropy, and deep metric learning, within the context of MI-EEG. We evaluate AlphaGrad using two state-of-the-art MTL-based 
            neural networks, MIN2Net and FBMSNet, across four benchmark datasets. Experimental results show that AlphaGrad consistently outperforms existing strategies 
            such as AdaMT, GradApprox, and fixed-weight baselines in classification accuracy and training stability. Compared to baseline static weighting, 
            AlphaGrad achieves over 10% accuracy improvement on subject-independent MI tasks when evaluated on the largest benchmark dataset. Furthermore, 
            AlphaGrad demonstrates robust adaptability across various EEG paradigms—including steady-state visually evoked potential (SSVEP) and event-related potential (ERP), 
            making it broadly applicable to brain-computer interface (BCI) systems. We also provide gradient trajectory visualizations highlighting AlphaGrad’s ability to 
            maintain training stability and avoid local minima. These findings underscore AlphaGrad’s promise as a general-purpose solution for adaptive multi-loss optimization 
            in biomedical time-series learning.
          </p>
        </div>
      </div>
    </div>
    <!--/ Abstract. -->
  </div>
</section>
<!-- 
<section class="section">
  <div class="container is-max-desktop">

    <div class="columns is-centered">

      <div class="column">
        <div class="content">
          <h2 class="title is-3">Classification accuracy of different models across subjects</h2>
          <p>
            The figure presents the classification accuracy of different models across subjects in the OpenBMI dataset for a 3-class motor imagery (MI) task, evaluated under a 5-fold cross-validation setting. The subjects are ordered by ascending performance, allowing for clearer model comparison. The results show that FBMSNet-AlphaGrad consistently achieves the highest accuracy for most subjects, indicating its superior performance compared to other methods. MIN2Net-AlphaGrad closely follows, demonstrating competitive and stable results.
          </p>
          <img src="./static/images/subject_accuracy.png"
               alt="Classification accuracy"
               class="image normal-img-scale-center"
               id="clickable-image">
        </div>
      </div>

      <div class="column">
        <h2 class="title is-3">Subject-wise accuracy difference</h2>
        <div class="columns is-centered">
          <div class="column content">
            <p>
              Subject-wise accuracy difference (%) between AlphaGrad (used as the reference) and other loss blending strategies for (a) MIN2Net and (b) FBMSNet in MI multi-class classification on the OpenBMI dataset. Negative values indicate lower performance compared to AlphaGrad. The results highlight the consistent performance advantage of AlphaGrad, particularly when used with FBMSNet.
            </p>
            <img src="./static/images/diff_acc.png"
                 alt="Subject-wise accuracy difference"
                 class="image normal-img-scale-center"
                 id="clickable-image">
          </div>

        </div>
      </div>
    </div>

  </div>
</section> -->

<section class="section">
  <div class="container is-max-desktop">

    <div class="columns is-centered">

      <!-- Classification accuracy -->
      <div class="column">
        <div class="content">
          <h2 class="title is-3">Classification accuracy of different models across subjects</h2>
          <p>
            The figure presents the classification accuracy of different models across subjects in the OpenBMI dataset for a 3-class motor imagery (MI) task, evaluated under a 5-fold cross-validation setting...
          </p>
          <img src="./static/images/subject_accuracy.png"
               alt="Classification accuracy"
               class="image normal-img-scale-center"
               id="clickable-image-1">
        </div>
      </div>

      <!-- Subject-wise accuracy difference -->
      <div class="column">
        <h2 class="title is-3">Subject-wise accuracy difference</h2>
        <div class="columns is-centered">
          <div class="column content">
            <p>
              Subject-wise accuracy difference (%) between AlphaGrad (used as the reference) and other loss blending strategies...
            </p>
            <img src="./static/images/diff_acc.png"
                 alt="Subject-wise accuracy difference"
                 class="image normal-img-scale-center"
                 id="clickable-image-2">
          </div>
        </div>
      </div>

    </div>
  </div>
</section>

<!-- Modal for image 1 -->
<div class="modal" id="image-modal-1">
  <div class="modal-background"></div>
  <div class="modal-content">
    <img src="./static/images/subject_accuracy.png" alt="Classification accuracy">
  </div>
  <button class="modal-close is-large" aria-label="close"></button>
</div>

<!-- Modal for image 2 -->
<div class="modal" id="image-modal-2">
  <div class="modal-background"></div>
  <div class="modal-content">
    <img src="./static/images/diff_acc.png" alt="Subject-wise accuracy difference">
  </div>
  <button class="modal-close is-large" aria-label="close"></button>
</div>


<section class="section">
  <div class="container is-fullwidth">

    <div class="content">
      <h2 class="title is-3">Trajectory of gradient descent (GD) for a multi-task objective</h2>
      <p>
      Apart from AlphaGrad, the gradient descent trajectories of the other strategies become trapped in local minima for up to two of the three initial parameter sets. 
      This behavior indicates that the gradient of one task overshadows the other, causing the optimization process to oscillate between the steep valley walls without significant progress along the valley floor
      </p>
    </div>
    
    <div class="columns is-centered">
       <!-- Objective -->
    <div class="column">
      <div class="content">
        <h2 class="title is-6 h-center">Multi-task Objective</h2>
        <img src="./static/images/toys/3d-obj.png"
             alt="Baseline"
             class="image img-scale-center">
      </div>
    </div>
    <!--/ Objective -->

      <!-- Baseline -->
      <div class="column">
        <div class="content">
          <h2 class="title is-6 h-center">Baseline</h2>
          <video id="dollyzoom" autoplay muted loop playsinline height="100%">
            <source src="./static/videos/Fixed-video.mp4"
                    type="video/mp4">
          </video>
        </div>
      </div>
      <!--/ Baseline -->

      <!-- GradApprox -->
      <div class="column">
        <div class="content">
          <h2 class="title is-6 h-center">GradApprox</h2>
          <video id="dollyzoom" autoplay muted loop playsinline height="100%">
            <source src="./static/videos/GradApprox-video.mp4"
                    type="video/mp4">
          </video>
        </div>
      </div>
      <!--/ GradApprox -->

      <!-- AdaMT -->
      <div class="column">
        <div class="content">
          <h2 class="title is-6 h-center">AdaMT</h2>
          <video id="dollyzoom" autoplay muted loop playsinline height="100%">
            <source src="./static/videos/AdaMT-video.mp4"
                    type="video/mp4">
          </video>
        </div>
      </div>
      <!--/ AdaMT -->

      <!-- AlphaGrad -->
      <div class="column">
        <div class="content">
          <h2 class="title is-6 h-center">AlphaGrad</h2>
          <video id="dollyzoom" autoplay muted loop playsinline height="100%">
            <source src="./static/videos/AlphaGrad-video.mp4"
                    type="video/mp4">
          </video>
        </div>
      </div>
      <!--/ AlphaGrad -->
    </div>
  </div>
</section>

<section class="section" id="BibTeX">
  <div class="container is-max-desktop content">
    <h2 class="title">BibTeX</h2>
  </div>
  <div class="code-block-container">
    <div class="code-block-header">
      <span class="language-label">BibTeX</span>
      <button class="copy-button" onclick="copyToClipboard(this, 'bibtex-code')">Copy</button>
    </div>
    <pre><code id="bibtex-code">@ARTICLE{11008918,
  author    = {Chaisaen, Rattanaphon and Autthasan, Phairot and Ditthapron, Apiwat and Wilaiprasitporn, Theerawit},
  journal   = {IEEE Journal of Biomedical and Health Informatics},
  title     = {AlphaGrad: Normalized Gradient Descent for Adaptive Multi-loss Functions in EEG-based Motor Imagery Classification},
  year      = {2025},
  volume    = {},
  number    = {},
  pages     = {1-13},
  keywords  = {Brain-computer interfaces;multi-task learning;adaptive loss blending;motor imagery EEG;normalized gradient descent;},
  doi       = {10.1109/JBHI.2025.3572197}
}</code></pre>
  </div>
</section>

<footer class="footer">
  <div class="container">
    <div class="content has-text-centered">
      <a class="icon-link"
         href="https://doi.org/10.1109/JBHI.2025.3572197">
        <i class="fas fa-file-pdf"></i>
      </a>
      <a class="icon-link" href="https://github.com/xydxdy/AlphaGrad/" class="external-link">
        <i class="fab fa-github"></i>
      </a>
    </div>
    <div class="columns is-centered">
      <div class="column is-8">
        <div class="content">
          <p>
            This website is licensed under a <a rel="license"
                                                href="http://creativecommons.org/licenses/by-sa/4.0/">Creative
            Commons Attribution-ShareAlike 4.0 International License</a>.
          </p>
          <p>
            This means you are free to borrow the <a
              href="https://github.com/nerfies/nerfies.github.io">source code</a> of this website,
            we just ask that you link back to this page in the footer.
            Please remember to remove the analytics code included in the header of the website which
            you do not want on your website.
          </p>
        </div>
      </div>
    </div>
  </div>
</footer>

</body>
</html>
